import { Request, Response } from 'express';
import { MinIOModel } from '../models/minio.model';
import { DocumentService } from '../services/document.service';
import { EmbeddingService } from '../services/embedding.service';
import { DatabaseModel } from '../models/database.model';

export class IngestController {
  constructor(
    private minio: MinIOModel,
    private documentService: DocumentService,
    private embeddingService: EmbeddingService,
    private db: DatabaseModel
  ) {}

  // üöÄ INGEST TO√ÄN B·ªò BUCKET SYLLABUS
  async ingestAll(req: Request, res: Response) {
    try {
      const basePrefix = 'chatbot courses';
      const folders = ['ctdt-co-dau-moc', 'de-cuong', 'quy-che-hoc-vu'];
      
      let totalFiles = 0;
      let totalChunks = 0;
      const errors: string[] = [];

      for (const folder of folders) {
        const prefix = `${basePrefix}/${folder}/`;
        
        console.log(`üìÇ Scanning folder: ${prefix}`);
        
        try {
          const files = await this.minio.listFiles(prefix);
          console.log(`Found ${files.length} files in ${folder}`);

          for (const objectName of files) {
            // B·ªè qua th∆∞ m·ª•c
            if (objectName.endsWith('/')) continue;
            
            // Ch·ªâ l·∫•y file .docx
            if (!objectName.toLowerCase().endsWith('.docx')) {
              console.log(`‚è≠Ô∏è Skipping non-docx file: ${objectName}`);
              continue;
            }

            console.log(`üì• Processing: ${objectName}`);
            
            try {
              totalFiles++;

              // Download file t·ª´ MinIO
              const buffer = await this.minio.getFile(objectName);
              console.log(`  ‚úì Downloaded ${buffer.length} bytes`);

              // Extract text t·ª´ docx
              const rawText = await this.documentService.extractText(buffer, objectName);
              console.log(`  ‚úì Extracted ${rawText.length} characters`);

              // Clean text
              const text = this.documentService.cleanText(rawText);
              
              if (!text || text.trim().length === 0) {
                console.log(`  ‚ö†Ô∏è No text content after cleaning, skipping`);
                continue;
              }

              // Chunk text
              const chunks = this.documentService.chunkText(text, 300, 50);
              console.log(`  ‚úì Created ${chunks.length} chunks`);

              // Insert document v√†o DB ƒë·ªÉ l·∫•y UUID
              const documentId = await this.db.insertDocument({
                filename: objectName.split('/').pop() || objectName,
                file_path: objectName,
                file_size: buffer.length,
                content_type: 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
              });

              console.log(`  ‚úì Document inserted with ID: ${documentId}`);

              // Embed v√† save t·ª´ng chunk
              for (let i = 0; i < chunks.length; i++) {
                const embedding = await this.embeddingService.generateEmbedding(chunks[i]);
                
                await this.db.insertChunk({
                  document_id: documentId,
                  content: chunks[i],
                  chunk_index: i,
                  embedding,
                });

                totalChunks++;
                
                // Log progress m·ªói 10 chunks
                if ((i + 1) % 10 === 0) {
                  console.log(`  ‚úì Processed ${i + 1}/${chunks.length} chunks`);
                }
              }

              console.log(`‚úÖ Successfully ingested: ${objectName} (${chunks.length} chunks)`);

            } catch (fileError: any) {
              const errorMsg = `Error processing ${objectName}: ${fileError.message}`;
              console.error(`‚ùå ${errorMsg}`);
              errors.push(errorMsg);
              // Ti·∫øp t·ª•c v·ªõi file ti·∫øp theo
            }
          }
        } catch (folderError: any) {
          const errorMsg = `Error scanning folder ${folder}: ${folderError.message}`;
          console.error(`‚ùå ${errorMsg}`);
          errors.push(errorMsg);
        }
      }

      console.log(`\nüéâ Ingest completed!`);
      console.log(`üìä Total files processed: ${totalFiles}`);
      console.log(`üì¶ Total chunks created: ${totalChunks}`);
      if (errors.length > 0) {
        console.log(`‚ö†Ô∏è Errors encountered: ${errors.length}`);
      }

      res.json({
        message: 'Ingest ho√†n t·∫•t',
        totalFiles,
        totalChunks,
        errors: errors.length > 0 ? errors : undefined,
        folders: folders
      });

    } catch (error: any) {
      console.error('‚ùå Ingest failed:', error);
      res.status(500).json({ 
        error: error.message,
        stack: process.env.NODE_ENV === 'development' ? error.stack : undefined
      });
    }
  }

  // Ki·ªÉm tra tr·∫°ng th√°i ingest
  async checkIngestStatus(req: Request, res: Response) {
    try {
      const stats = await this.db.getIngestStats();
      res.json({
        summary: {
          totalDocuments: stats.totalDocuments,
          totalChunks: stats.totalChunks
        },
        documents: stats.documents
      });
    } catch (error: any) {
      console.error('Check status failed:', error);
      res.status(500).json({ error: error.message });
    }
  }
  // X√ìA TO√ÄN B·ªò D·ªÆ LI·ªÜU INGEST
async clearAll(req: Request, res: Response) {
  try {
    const chunksResult = await this.db['pool'].query(
      'DELETE FROM chunks RETURNING id'
    );
    
    const docsResult = await this.db['pool'].query(
      'DELETE FROM documents RETURNING id'
    );
    
    console.log(`Deleted ${chunksResult.rowCount} chunks`);
    console.log(`Deleted ${docsResult.rowCount} documents`);
    
    res.json({
      message: 'ƒê√£ x√≥a to√†n b·ªô d·ªØ li·ªáu ingest',
      deletedChunks: chunksResult.rowCount,
      deletedDocuments: docsResult.rowCount
    });
  } catch (error: any) {
    console.error('Clear failed:', error);
    res.status(500).json({ error: error.message });
  }
}
}